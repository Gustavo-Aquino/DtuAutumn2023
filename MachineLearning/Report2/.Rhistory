y
length(y)
length(x)
length(x[1,])
length(x[,1])
predicted_classes_tree
test_labels
train_labels
test_labels
g_data <- cbind(X,y)
x <- model.matrix(y ~ ., g_data)
# regularization #
set.seed(321)  # Set a seed for reproducibility
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
train_data <- x[train_index, ]
test_data <- x[-train_index, ]
train_labels <- y[train_index]
test_labels <- y[-train_index]
cv_model <- cv.glmnet(x = train_data, y = train_labels, family = "multinomial", alpha = 0)
best_lambda <- cv_model$lambda.min
# Fit a multinomial logistic regression model
final_model <- glmnet(x = train_data, y = train_labels, family = "multinomial", alpha = 0, lambda = best_lambda)
model_tree <- rpart(y ~ ., data = g_data, method = "class")
# Make predictions on new data
predictions <- predict(final_model, s = best_lambda, newx = test_data, type = "response")
predicted_classes <- as.numeric(colnames(predictions)[apply(predictions, 1, which.max)])
predicted_classes_tree <- as.numeric(predict(model_tree, newx = test_data, type = "class"))
predicted_classes
predicted_classes_tree
test_data
train_data
x[-train_index, ]
train_index
length(train_index)
length(train_data)
length(test_data)
test_data
predicted_classes_tree
predicted_class_tree <- predict(model_tree, newdata = new_data, type = "class")
predicted_class_tree <- predict(model_tree, newdata = test_data, type = "class")
predicted_class_tree <- predict(model_tree, newdata = test_data, type = "class")
predicted_class_tree <- predict(model_tree, newdata = as.dataframe(test_data), type = "class")
predicted_class_tree <- predict(model_tree, newdata = as.data.frame(test_data), type = "class")
predicted_class_tree
predicted_class_tree <- as.numeric(predict(model_tree, newdata = as.data.frame(test_data), type = "class"))
predicted_class_tree
conf_matrix <- confusionMatrix(predicted_classes_tree, test_labels, mode = 'everything')
predicted_class_tree <- factor(predicted_class_tree, levels = c(0:5))
conf_matrix <- confusionMatrix(predicted_classes_tree, test_labels, mode = 'everything')
predicted_classes_tree
predicted_classes_tree <- as.numeric(predict(model_tree, newdata = as.data.frame(test_data), type = "class"))
predicted_classes_tree <- factor(predicted_class_tree, levels = c(0:5))
conf_matrix <- confusionMatrix(predicted_classes_tree, test_labels, mode = 'everything')
predicted_classes_tree <- factor(predicted_class_tree, levels = c(1:5))
conf_matrix <- confusionMatrix(predicted_classes_tree, test_labels, mode = 'everything')
predicted_classes_tree
test_labels
test_labels <- factor(test_labels, levels = c(1:5))
predicted_classes_tree <- as.numeric(predict(model_tree, newdata = as.data.frame(test_data), type = "class"))
predicted_classes_tree <- factor(predicted_class_tree, levels = c(1:5))
conf_matrix <- confusionMatrix(predicted_classes_tree, test_labels, mode = 'everything')
print("Confusion Matrix:")
print(conf_matrix)
library(class)
test_data
train_data <- g_data[train_index, ]
test_data <- g_data[-train_index, ]
train_data
cv_model <- cv.glmnet(x = train_data, y = train_labels, family = "multinomial", alpha = 0)
k <- 3  # Number of neighbors to consider
model_knn <- knn(train_data, test_data, k)
model_knn <- knn(train_data, test_data, train_labels,k)
model_knn
conf_matrix <- confusionMatrix(model_knn, test_labels, mode = 'everything')
model_knn
test_labels
g_data <- cbind(X,y)
x <- model.matrix(y ~ ., g_data)
# regularization #
set.seed(321)  # Set a seed for reproducibility
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
train_data <- x[train_index, ]
test_data <- x[-train_index, ]
train_labels <- y[train_index]
test_labels <- y[-train_index]
test_labels <- factor(test_labels, levels = c(1:5))
test_labels
test_labels <- y[-train_index]
test_labels <- factor(test_labels, levels = c(0:5))
test_labels
conf_matrix <- confusionMatrix(model_knn, test_labels, mode = 'everything')
print("Confusion Matrix:")
print(conf_matrix)
data <- read.csv("C:\\Faculdade\\Intercâmbio\\Process Mining\\Recorded_Business_Tasks.csv")
library(readr)
data <- read.csv("C:\\Faculdade\\Intercâmbio\\Process Mining\\Recorded_Business_Tasks.csv")
library(readr)
data <- read.csv("C:\\Faculdade\\Intercâmbio\\Process Mining\\final_project\\Recorded_Business_Tasks.csv")
View(data)
data[,c('RecordingId','ApplicationProcessName')]
recording_connector <- unique(data[,c('RecordingId','ApplicationProcessName')])
recording_connector
View(recording_connector)
recording_connector <- unique(data[,c('RecordingId','ApplicationProcessName')]) %>% filter(!is.na('ApplicationProcessName'))
library(dplyr)
recording_connector <- unique(data[,c('RecordingId','ApplicationProcessName')]) %>% filter(!is.na('ApplicationProcessName'))
recording_connector
View(recording_connector)
head(recording_connector)
recording_connector[1,2]
recording_connector <- unique(data[,c('RecordingId','ApplicationProcessName')]) %>%
filter(!is.na('ApplicationProcessName')|ApplicationProcessName == '')
recording_connector
recording_connector <- unique(data[,c('RecordingId','ApplicationProcessName')]) %>%
filter(!is.na('ApplicationProcessName')) %>%
filter(ApplicationProcessName == "")
recording_connector
recording_connector <- unique(data[,c('RecordingId','ApplicationProcessName')]) %>%
filter(!is.na('ApplicationProcessName')) %>%
filter(ApplicationProcessName != "")
View(recording_connector)
unique(recording_connector$ApplicationProcessName)
library(readr)
library(dplyr)
data <- read.csv("C:\\Faculdade\\Intercâmbio\\Process Mining\\final_project\\Recorded_Business_Tasks.csv")
recording_connector <- unique(data[,c('RecordingId','ApplicationProcessName')]) %>%
filter(!is.na('ApplicationProcessName')) %>%
filter(ApplicationProcessName != "")
unique(recording_connector$ApplicationProcessName)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t_split <- test_split()
t_deph <- test_deph()
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/graphs.R", echo=TRUE)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t <- default()
t
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t <- default()
t
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t
t <- default()
t
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t <- default()
t
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t <- default()
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t <- default()
t
t[[2]]
t[[2]] %>% select(-c(k_neighbors, KNN_E_test))
mean(t[[2]]$minsplit)
mean(t[[2]]$minsplit[-10,])
(t[[2]]$minsplit[-10,])
(t[[2]]$minsplit[-10])
mean(t[[2]]$minsplit[-10])
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
t_split <- test_split()
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/graphs.R", echo=TRUE)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/graphs.R", echo=TRUE)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/graphs.R", echo=TRUE)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/graphs.R", echo=TRUE)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/graphs.R", echo=TRUE)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/graphs.R", echo=TRUE)
t
t[[1]]
test <- t[[1]][-1,]
mcnemar(test$actual, test$ct, test$multinom)
test <- test %>% mutate(across(everything(), ~as.numeric(.x)))
mcnemar(test$actual, test$ct, test$multinom)
mcnemar(test$actual, test$ct, test$baseline)
mcnemar(test$actual, test$multinom, test$baseline)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
default()
default()
best_multinom_model
View(best_multinom_model)
coef(best_multinom_model)
coefficients <- coef(best_multinom_model)
# Function to convert log-odds to probabilities
logodds_to_prob <- function(logodds_matrix) {
odds_matrix <- exp(logodds_matrix)
prob_matrix <- odds_matrix / rowSums(odds_matrix)
return(prob_matrix)
}
# Apply the function to each set of coefficients
probabilities <- lapply(coefficients, logodds_to_prob)
# Print the probabilities
print(probabilities)
source("C:/Faculdade/Intercâmbio/Machine Learning/Report2/report2.R", echo=TRUE)
data <- read.csv("glass.data")
data_t <- data
# Add class names to the dataset
data$typeName[data$Type == 1] <- "Building, float"
data$typeName[data$Type == 2] <- "Building, non-float"
data$typeName[data$Type == 3] <- "Vehicle, float"
data$typeName[data$Type == 4] <- "Vehicle, non-float"
data$typeName[data$Type == 5] <- "Container"
data$typeName[data$Type == 6] <- "Tableware"
data$typeName[data$Type == 7] <- "Headlamp"
# Remove numeric class attribute as there is one missing type
data <- data %>%
select(-Type)
# Extract attributes (features)
X <- data[, 2:10]
classLabels <- data[, 11]
# Check and record dimensions
(N <- nrow(X))
(M <- ncol(X))
# Extract numeric class assignments
y <- as.numeric(as.factor(classLabels)) - 1
# Implement two-level cross-validation
K1 <- 10  # Number of outer folds
K2 <- 10  # Number of inner folds
possible_k_neighbors <- c(1:40)
possible_minsplit <- seq(1:80)
# some machines may have problem running with a lambda as low as 0.01,
# this is a problem with glmnet function that we couldn't resolve even with TA's help
# but we can see the convergence to better results as lambda approaches zero
possible_lambda <- seq(0.04, 1, 0.01)
classifier_results <- tribble(~ct, ~multinom, ~baseline, ~actual,
NA,NA,NA,NA)
table_results <- data.frame(OuterFold = numeric(0), CT_E_test = numeric(0), k_neighbors = numeric(0), KNN_E_test = numeric(0), lambda = numeric(0), MultinomRegression_E_test = numeric(0), Baseline_E_test = numeric(0))
# Implement two-level cross-validation
set.seed(123)  # Set a seed for reproducibility
outer_folds <- createFolds(y, k = K1, list = TRUE)
preProcValues <- preProcess(X, method = c("center", "scale"))
for (i in 1:K1) {
outer_train_idx <- unlist(outer_folds[-i])
outer_test_idx <- unlist(outer_folds[i])
# Inner folds for inner validation
inner_folds <- createFolds(y[outer_train_idx], k = K2, list = TRUE)
# inner loop for tuning k-nearest neighbors k
best_k <- 0
best_inner_mean_accuracy <- 0
for (k in possible_k_neighbors) {
inner_results <- c()  # Store inner loop results
for (j in 1:K2) {
inner_train_idx <- unlist(inner_folds[-j])
inner_validation_idx <- unlist(inner_folds[j])
# browser()
X_inner_train <- predict(preProcValues, X[inner_train_idx, ])
X_inner_validation <- predict(preProcValues, X[inner_validation_idx, ])
y_inner_train <- y[inner_train_idx]
y_inner_validation <- y[inner_validation_idx]
# Train an KNN with k neighbors
knn_model <- knn(train = X_inner_train, test = X_inner_validation, cl = y_inner_train, k = k, algorithm = "kd_tree")
knn_accuracy <- sum(knn_model == y_inner_validation) / length(y_inner_validation)
inner_results <- c(inner_results, knn_accuracy)
}
# Calculate the mean performance over inner validation folds for this model
inner_mean_accuracy <- mean(inner_results)
# Check if this model has a higher mean accuracy than the best one so far
if (inner_mean_accuracy > best_inner_mean_accuracy) {
best_inner_mean_accuracy <- inner_mean_accuracy
best_k <- k
}
}
# Calculate for the best KNN model
best_knn_predictions <- knn(
train = predict(preProcValues, X[outer_train_idx, ]),
test = predict(preProcValues, X[outer_test_idx, ]),
cl = y[outer_train_idx], k = best_k
)
best_knn_E_test <- sum(best_knn_predictions != y[outer_test_idx]) / length(y[outer_test_idx])
# inner loop for tuning Classification tree
best_min <- 0
best_ct_model <- NULL
best_inner_mean_accuracy <- 0
for (minsplit in possible_minsplit) {
inner_results <- c()  # Store inner loop results
for (j in 1:K2) {
inner_train_idx <- unlist(inner_folds[-j])
inner_validation_idx <- unlist(inner_folds[j])
X_inner_train <- X[inner_train_idx, ]
X_inner_validation <- X[inner_validation_idx, ]
y_inner_train <- y[inner_train_idx]
y_inner_validation <- y[inner_validation_idx]
ct_model <- rpart(y_inner_train ~ ., data = X_inner_train,
control = rpart.control(minsplit = minsplit, minbucket = 5, cp = 0),
parms = list(split = "gini"), method = "class")
ct_predictions <- predict(ct_model, X_inner_validation, type = "class")
ct_accuracy <- sum(ct_predictions == y_inner_validation) / length(y_inner_validation)
inner_results <- c(inner_results, ct_accuracy)
}
# Calculate the mean performance over inner validation folds for this model
inner_mean_accuracy <- mean(inner_results)
# Check if this model has a higher mean accuracy than the best one so far
if (inner_mean_accuracy > best_inner_mean_accuracy) {
best_inner_mean_accuracy <- inner_mean_accuracy
best_minsplit <- minsplit
best_ct_model <- ct_model
}
}
best_ct_predictions <- predict(best_ct_model, X[outer_test_idx, ], type = "class")
best_ct_E_test <- sum(best_ct_predictions != y[outer_test_idx]) / length(y[outer_test_idx])
prp(best_ct_model)
# inner loop for tuning Multinomial regression
best_lambda <- 0
best_multinom_model <- NULL
best_inner_mean_accuracy <- 0
for(regularization_strength in possible_lambda){
inner_results <- c()
for (j in 1:K2) {
inner_train_idx <- unlist(inner_folds[-j])
inner_validation_idx <- unlist(inner_folds[j])
X_inner_train <- X[inner_train_idx, ]
X_inner_validation <- X[inner_validation_idx, ]
y_inner_train <- y[inner_train_idx]
y_inner_validation <- y[inner_validation_idx]
multinom_model <- glmnet(predict(preProcValues, X[inner_train_idx, ]), y[inner_train_idx],
family = "multinomial", alpha = 0, lambda = regularization_strength)
multinom_predictions <- predict(multinom_model,
as.matrix(predict(preProcValues, X[inner_validation_idx, ])),
type = 'class', s = regularization_strength)
multinom_accuracy <- sum(multinom_predictions == y_inner_validation) / length(y_inner_validation)
inner_results <- c(inner_results, multinom_accuracy)
}
# Calculate the mean performance over inner validation folds for this model
inner_mean_accuracy <- mean(inner_results)
# Check if this model has a higher mean accuracy than the best one so far
if (inner_mean_accuracy > best_inner_mean_accuracy) {
best_inner_mean_accuracy <- inner_mean_accuracy
best_lambda <- regularization_strength
best_multinom_model <- multinom_model
}
}
# browser()
# Calculate the multinomial regression E_test
best_multinom_predictions <- predict(best_multinom_model,
newx = as.matrix(predict(preProcValues, X[outer_test_idx, ])),
type = 'class', s = best_multinom_model$lambda)
multinom_regression_E_test <- sum(best_multinom_predictions != y[outer_test_idx]) / length(y[outer_test_idx])
# Calculate the baseline E_test
baseline_predictions <- rep(names(sort(table(y[outer_train_idx]), decreasing = TRUE))[1], length(outer_test_idx))
baseline_E_test <- sum(baseline_predictions != y[outer_test_idx]) / length(y[outer_test_idx])
# Add the results to the data frame
table_results <- rbind(table_results,
data.frame(
OuterFold = i,
minsplit = best_minsplit, CT_E_test = best_ct_E_test,
k_neighbors = best_k, KNN_E_test = best_knn_E_test,
lambda = best_lambda, MultinomRegression_E_test = multinom_regression_E_test,
Baseline_E_test = baseline_E_test
)
)
# Add the predictions to the data frame
classifier_results <- rbind(
classifier_results,
c(list(best_ct_predictions), list(best_multinom_predictions), list(baseline_predictions), list(y[outer_test_idx]))
)
}
best_multinom_model
coefficients <- coef(best_multinom_model)
coefficients
logodds_to_prob <- function(logodds_matrix) {
odds_matrix <- exp(logodds_matrix)
prob_matrix <- odds_matrix / rowSums(odds_matrix)
return(prob_matrix)
}
logodds_to_prob
probabilities <- lapply(coefficients, logodds_to_prob)
probabilities
coefficients <- coef(best_multinom_model)
# Function to convert log-odds to probabilities for each level
logodds_to_prob <- function(logodds_array) {
odds_array <- exp(logodds_array)
prob_array <- odds_array / rowSums(odds_array, dims = 2)  # Normalize across categories
return(prob_array)
}
# Apply the function to each set of coefficients
probabilities <- lapply(1:ncol(coefficients), function(i) logodds_to_prob(coefficients[, , i]))
coefficients <- coef(best_multinom_model)
coefficients
coefficients <- coef(best_multinom_model)
# Function to apply softmax to a vector
softmax <- function(x) {
exp_x <- exp(x - max(x))  # Subtracting max(x) for numerical stability
return(exp_x / sum(exp_x))
}
# Extracting coefficients for each level
coef_level_0 <- as.vector(coefficients[[1]])
coef_level_1 <- as.vector(coefficients[[2]])
coef_level_2 <- as.vector(coefficients[[3]])
coef_level_3 <- as.vector(coefficients[[4]])
coef_level_4 <- as.vector(coefficients[[5]])
coef_level_5 <- as.vector(coefficients[[6]])
# Applying softmax to obtain probabilities
probabilities_0 <- softmax(coef_level_0)
probabilities_1 <- softmax(coef_level_1)
probabilities_2 <- softmax(coef_level_2)
probabilities_3 <- softmax(coef_level_3)
probabilities_4 <- softmax(coef_level_4)
probabilities_5 <- softmax(coef_level_5)
# Displaying the probabilities
cat("Probabilities for Level 0:", probabilities_0, "\n")
cat("Probabilities for Level 1:", probabilities_1, "\n")
cat("Probabilities for Level 2:", probabilities_2, "\n")
cat("Probabilities for Level 3:", probabilities_3, "\n")
cat("Probabilities for Level 4:", probabilities_4, "\n")
cat("Probabilities for Level 5:", probabilities_5, "\n")
coefficients <- as.data.frame(coef(fit))
coefficients <- as.data.frame(coef(best_multinom_model))
coefficients <- coef(best_multinom_model)
# Convert each matrix to a dense matrix
dense_matrices <- lapply(coefficients, as.matrix)
# Convert to a data frame
coefficients_df <- as.data.frame(dense_matrices)
# Print the resulting data frame
print(coefficients_df)
coefficients_df <- t(as.data.frame(dense_matrices))
print(coefficients_df)
View(coefficients_df)
coefficients_df <- as.data.frame(dense_matrices)
coefficients_df
coefficients_df <- t(as.data.frame(dense_matrices))
coefficients_df
column_means <- sapply(coefficients_df, function(x) mean(abs(x)))
print(column_means)
View(coefficients_df)
column_means <- apply(coefficients_df, 2, function(x) mean(abs(x)))
print(column_means)
y <- as.numeric(as.factor(classLabels)) - 1
y
classLabels
source("~/.active-rstudio-document", echo=TRUE)
# Function to calculate softmax transformation
softmax <- function(x) {
exp_x <- exp(x - max(x))  # Subtracting max(x) for numerical stability
return(exp_x / sum(exp_x))
}
# Given weights
w1 <- c(1.2, -2.1, 3.2)
w2 <- c(1.2, -1.7, 2.9)
w3 <- c(1.3, -1.1, 2.2)
# Given coordinates
coordinates <- matrix(c(-1.4, 2.6, -0.6, -1.6, 2.1, 5.0, 0.7, 3.8), ncol = 2)
# Calculate softmax counts for each observation
for (i in 1:nrow(coordinates)) {
# Calculate y_hat for each class
y_hat_1 <- c(1, coordinates[i,]) %*% w1
y_hat_2 <- c(1, coordinates[i,]) %*% w2
y_hat_3 <- c(1, coordinates[i,]) %*% w3
# Softmax transformation
softmax_probs <- softmax(c(y_hat_1, y_hat_2, y_hat_3, 0))  # Adding 0 for class 4
# Print the results
cat("Observation", i, "Probabilities:", softmax_probs, "\n")
}
# Given weights
w1 <- c(1.2, -2.1, 3.2)
w2 <- c(1.2, -1.7, 2.9)
w3 <- c(1.3, -1.1, 2.2)
# Given coordinates
coordinates <- matrix(c(-1.4, 2.6, -0.6, -1.6, 2.1, 5.0, 0.7, 3.8), ncol = 2)
# Function to calculate softmax transformation
softmax <- function(x) {
exp_x <- exp(x - max(x))  # Subtracting max(x) for numerical stability
return(exp_x / sum(exp_x))
}
# Calculate softmax counts for each observation
results <- matrix(0, nrow = nrow(coordinates), ncol = 4)
for (i in 1:nrow(coordinates)) {
# Calculate y_hat for each class
y_hat_1 <- c(1, coordinates[i,]) %*% w1
y_hat_2 <- c(1, coordinates[i,]) %*% w2
y_hat_3 <- c(1, coordinates[i,]) %*% w3
# Softmax transformation
softmax_probs <- softmax(c(y_hat_1, y_hat_2, y_hat_3, 0))  # Adding 0 for class 4
# Store the results
results[i,] <- softmax_probs
}
# Print the results
cat("Observation Probabilities (Class 1, Class 2, Class 3, Class 4):\n")
print(results)
coordinates <- matrix(c(-1.4, 2.6, -0.6, -1.6, 2.1, 5.0, 0.7, 3.8), ncol = 2)
coordinates
softmax_probs
sum(softmax_probs)
# Given weights
w1 <- c(1.2, -2.1, 3.2)
w2 <- c(1.2, -1.7, 2.9)
w3 <- c(1.3, -1.1, 2.2)
# Given coordinates for each observation
coordinates <- list(c(-1.4, 2.6), c(-0.6, -1.6), c(2.1, 5.0), c(0.7, 3.8))
# Function to calculate softmax probabilities
softmax <- function(y) {
exp_y <- exp(y)
softmax_probs <- exp_y / sum(exp_y)
return(softmax_probs)
}
# Function to calculate per-class probabilities for an observation
calculate_probabilities <- function(b1, b2) {
# Calculate ŷ for each class
y1 <- c(1, b1, b2) %*% w1
y2 <- c(1, b1, b2) %*% w2
y3 <- c(1, b1, b2) %*% w3
# Apply softmax transformation
probs <- softmax(c(y1, y2, y3, 0))  # For k = 4
return(probs)
}
# Calculate probabilities for each observation
for (i in 1:length(coordinates)) {
b1 <- coordinates[[i]][1]
b2 <- coordinates[[i]][2]
# Calculate probabilities for the current observation
probabilities <- calculate_probabilities(b1, b2)
# Print results
cat("Observation", i, "Probabilities:", probabilities, "\n")
}
